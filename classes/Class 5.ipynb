{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53fce03f",
   "metadata": {},
   "source": [
    "## Module 5 Class activities\n",
    "This notebook is a starting point for the exercises and activities that we'll do in class. We'll do an extension of the random forests classifier, looking at a continuous variable.\n",
    "\n",
    "Before you attempt any of these activities, make sure to watch the video lectures for this module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c092609b",
   "metadata": {},
   "source": [
    "### Classification: NYC evictions\n",
    "We'll look at the factors that are associated with evictions in New York City. Perhaps a machine learning model can identify the types of places that are vulnerable to eviction, and target renter assistance programs more effectively?\n",
    "\n",
    "#### Loading in the data\n",
    "\n",
    "Let's start by loading in the [eviction dataset](https://data.cityofnewyork.us/City-Government/Evictions/6z8x-wfk4) via Socrata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30faed6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<strong>Exercise:</strong> Import the data from Socrata via the API into a pandas DataFrame.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479b86bd",
   "metadata": {},
   "source": [
    "*Hints*:\n",
    "- Look back at Week 1 if you need a refresher on using Socrata\n",
    "- There are about 70,000 rows in the dataset. So remember to add `?$limit=100000` to the end of the URL that you pass to `requests.get()`. Otherwise, you'll just get the first 1,000 rows. (The limit can be anything comfortably above 70000.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4133f155",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>court_index_number</th>\n",
       "      <th>docket_number</th>\n",
       "      <th>eviction_address</th>\n",
       "      <th>eviction_apt_num</th>\n",
       "      <th>executed_date</th>\n",
       "      <th>marshal_first_name</th>\n",
       "      <th>marshal_last_name</th>\n",
       "      <th>residential_commercial_ind</th>\n",
       "      <th>borough</th>\n",
       "      <th>eviction_zip</th>\n",
       "      <th>ejectment</th>\n",
       "      <th>eviction_possession</th>\n",
       "      <th>latitude</th>\n",
       "      <th>longitude</th>\n",
       "      <th>community_board</th>\n",
       "      <th>council_district</th>\n",
       "      <th>census_tract</th>\n",
       "      <th>bin</th>\n",
       "      <th>bbl</th>\n",
       "      <th>nta</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>60835/16</td>\n",
       "      <td>067937</td>\n",
       "      <td>800 ST. ANN'S AVENUE</td>\n",
       "      <td>11K</td>\n",
       "      <td>2018-02-13T00:00:00.000</td>\n",
       "      <td>Henry</td>\n",
       "      <td>Daley</td>\n",
       "      <td>Residential</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>10456</td>\n",
       "      <td>Not an Ejectment</td>\n",
       "      <td>Possession</td>\n",
       "      <td>40.820818</td>\n",
       "      <td>-73.910040</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>75</td>\n",
       "      <td>2117696</td>\n",
       "      <td>2026187501</td>\n",
       "      <td>Melrose South-Mott Haven North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>72503/19</td>\n",
       "      <td>107531</td>\n",
       "      <td>153-21 134TH AVENUE</td>\n",
       "      <td>2ND FLOOR</td>\n",
       "      <td>2022-03-28T00:00:00.000</td>\n",
       "      <td>Justin</td>\n",
       "      <td>Grossman</td>\n",
       "      <td>Residential</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>11434</td>\n",
       "      <td>Not an Ejectment</td>\n",
       "      <td>Possession</td>\n",
       "      <td>40.670269</td>\n",
       "      <td>-73.782793</td>\n",
       "      <td>12</td>\n",
       "      <td>28</td>\n",
       "      <td>294</td>\n",
       "      <td>4266194</td>\n",
       "      <td>4122780034</td>\n",
       "      <td>Springfield Gardens North</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3005/19</td>\n",
       "      <td>352734</td>\n",
       "      <td>533 TINTON AVENUE</td>\n",
       "      <td>53</td>\n",
       "      <td>2019-04-10T00:00:00.000</td>\n",
       "      <td>Thomas</td>\n",
       "      <td>Bia</td>\n",
       "      <td>Residential</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>10455</td>\n",
       "      <td>Not an Ejectment</td>\n",
       "      <td>Possession</td>\n",
       "      <td>40.812312</td>\n",
       "      <td>-73.906468</td>\n",
       "      <td>1</td>\n",
       "      <td>8</td>\n",
       "      <td>35</td>\n",
       "      <td>2003959</td>\n",
       "      <td>2025810028</td>\n",
       "      <td>Mott Haven-Port Morris</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>74543/18</td>\n",
       "      <td>21449</td>\n",
       "      <td>21-14 33RD AVENUE</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2019-01-30T00:00:00.000</td>\n",
       "      <td>Edward</td>\n",
       "      <td>Guida</td>\n",
       "      <td>Residential</td>\n",
       "      <td>QUEENS</td>\n",
       "      <td>11106</td>\n",
       "      <td>Not an Ejectment</td>\n",
       "      <td>Possession</td>\n",
       "      <td>40.764511</td>\n",
       "      <td>-73.932036</td>\n",
       "      <td>1</td>\n",
       "      <td>22</td>\n",
       "      <td>45</td>\n",
       "      <td>4006433</td>\n",
       "      <td>4005560127</td>\n",
       "      <td>Astoria</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>58634/16</td>\n",
       "      <td>322623</td>\n",
       "      <td>1776 CASTLE HILL AVENUE</td>\n",
       "      <td>1E</td>\n",
       "      <td>2017-03-29T00:00:00.000</td>\n",
       "      <td>John</td>\n",
       "      <td>Villanueva</td>\n",
       "      <td>Residential</td>\n",
       "      <td>BRONX</td>\n",
       "      <td>10462</td>\n",
       "      <td>Not an Ejectment</td>\n",
       "      <td>Possession</td>\n",
       "      <td>40.841803</td>\n",
       "      <td>-73.853212</td>\n",
       "      <td>10</td>\n",
       "      <td>18</td>\n",
       "      <td>204</td>\n",
       "      <td>2042266</td>\n",
       "      <td>2039980010</td>\n",
       "      <td>Westchester-Unionport</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  court_index_number docket_number         eviction_address eviction_apt_num   \n",
       "0           60835/16        067937     800 ST. ANN'S AVENUE              11K  \\\n",
       "1           72503/19        107531      153-21 134TH AVENUE        2ND FLOOR   \n",
       "2            3005/19        352734        533 TINTON AVENUE               53   \n",
       "3           74543/18         21449        21-14 33RD AVENUE              NaN   \n",
       "4           58634/16        322623  1776 CASTLE HILL AVENUE               1E   \n",
       "\n",
       "             executed_date marshal_first_name marshal_last_name   \n",
       "0  2018-02-13T00:00:00.000              Henry             Daley  \\\n",
       "1  2022-03-28T00:00:00.000             Justin          Grossman   \n",
       "2  2019-04-10T00:00:00.000             Thomas               Bia   \n",
       "3  2019-01-30T00:00:00.000             Edward             Guida   \n",
       "4  2017-03-29T00:00:00.000               John        Villanueva   \n",
       "\n",
       "  residential_commercial_ind borough eviction_zip         ejectment   \n",
       "0                Residential   BRONX        10456  Not an Ejectment  \\\n",
       "1                Residential  QUEENS        11434  Not an Ejectment   \n",
       "2                Residential   BRONX        10455  Not an Ejectment   \n",
       "3                Residential  QUEENS        11106  Not an Ejectment   \n",
       "4                Residential   BRONX        10462  Not an Ejectment   \n",
       "\n",
       "  eviction_possession   latitude   longitude community_board council_district   \n",
       "0          Possession  40.820818  -73.910040               1               17  \\\n",
       "1          Possession  40.670269  -73.782793              12               28   \n",
       "2          Possession  40.812312  -73.906468               1                8   \n",
       "3          Possession  40.764511  -73.932036               1               22   \n",
       "4          Possession  40.841803  -73.853212              10               18   \n",
       "\n",
       "  census_tract      bin         bbl                             nta  \n",
       "0           75  2117696  2026187501  Melrose South-Mott Haven North  \n",
       "1          294  4266194  4122780034       Springfield Gardens North  \n",
       "2           35  2003959  2025810028          Mott Haven-Port Morris  \n",
       "3           45  4006433  4005560127                         Astoria  \n",
       "4          204  2042266  2039980010           Westchester-Unionport  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "url = 'https://data.cityofnewyork.us/resource/6z8x-wfk4.json?$limit=100000'\n",
    "r = requests.get(url)\n",
    "evictions_df = pd.DataFrame(json.loads(r.text))\n",
    "evictions_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9549f5a2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<strong>Exercise:</strong> Convert your dataframe to a GeoDataFrame, using the latitude and longitude columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6e02f9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert to geodataframe\n",
    "evictionsGdf = gpd.GeoDataFrame(evictions_df, \n",
    "                                geometry=gpd.points_from_xy(evictions_df.longitude, evictions_df.latitude, \n",
    "                                crs='EPSG:4326'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5657ee",
   "metadata": {},
   "source": [
    "Now let's import some census data. We could use `cenpy` or the Census Bureau API. But to keep things simple so that we can focus on the spatial joins and the machine learning, I downloaded the block group-level 2019 ACS data for New York from the [Census Bureau](https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-data.html). To save space, I clipped it to the 5 NYC counties.\n",
    "\n",
    "It's in your repository, and we can load it in as follows. If you aren't familiar with a GeoPackage (GPKG) format, think of it as a \"new and improved shapefile.\" [Here's a good overview.](https://towardsdatascience.com/why-you-need-to-use-geopackage-files-instead-of-shapefile-or-geojson-7cb24fe56416)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "41d4aef5",
   "metadata": {},
   "outputs": [
    {
     "ename": "DriverError",
     "evalue": "data/nyc_bgs.gpkg: No such file or directory",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m                      Traceback (most recent call last)",
      "File \u001b[0;32mfiona/ogrext.pyx:136\u001b[0m, in \u001b[0;36mfiona.ogrext.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfiona/_err.pyx:291\u001b[0m, in \u001b[0;36mfiona._err.exc_wrap_pointer\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mCPLE_OpenFailedError\u001b[0m: data/nyc_bgs.gpkg: No such file or directory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mDriverError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m bgs \u001b[38;5;241m=\u001b[39m \u001b[43mgpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_file\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mdata/nyc_bgs.gpkg\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m bgs\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/anaconda3/envs/uds/lib/python3.10/site-packages/geopandas/io/file.py:259\u001b[0m, in \u001b[0;36m_read_file\u001b[0;34m(filename, bbox, mask, rows, engine, **kwargs)\u001b[0m\n\u001b[1;32m    256\u001b[0m     path_or_bytes \u001b[38;5;241m=\u001b[39m filename\n\u001b[1;32m    258\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfiona\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m--> 259\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read_file_fiona\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    260\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfrom_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbbox\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbbox\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmask\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrows\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrows\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    261\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m engine \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyogrio\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    263\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _read_file_pyogrio(\n\u001b[1;32m    264\u001b[0m         path_or_bytes, bbox\u001b[38;5;241m=\u001b[39mbbox, mask\u001b[38;5;241m=\u001b[39mmask, rows\u001b[38;5;241m=\u001b[39mrows, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    265\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/uds/lib/python3.10/site-packages/geopandas/io/file.py:303\u001b[0m, in \u001b[0;36m_read_file_fiona\u001b[0;34m(path_or_bytes, from_bytes, bbox, mask, rows, where, **kwargs)\u001b[0m\n\u001b[1;32m    300\u001b[0m     reader \u001b[38;5;241m=\u001b[39m fiona\u001b[38;5;241m.\u001b[39mopen\n\u001b[1;32m    302\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m fiona_env():\n\u001b[0;32m--> 303\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43mreader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_or_bytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m features:\n\u001b[1;32m    304\u001b[0m         crs \u001b[38;5;241m=\u001b[39m features\u001b[38;5;241m.\u001b[39mcrs_wkt\n\u001b[1;32m    305\u001b[0m         \u001b[38;5;66;03m# attempt to get EPSG code\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/uds/lib/python3.10/site-packages/fiona/env.py:457\u001b[0m, in \u001b[0;36mensure_env_with_credentials.<locals>.wrapper\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    454\u001b[0m     session \u001b[38;5;241m=\u001b[39m DummySession()\n\u001b[1;32m    456\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m env_ctor(session\u001b[38;5;241m=\u001b[39msession):\n\u001b[0;32m--> 457\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/uds/lib/python3.10/site-packages/fiona/__init__.py:335\u001b[0m, in \u001b[0;36mopen\u001b[0;34m(fp, mode, driver, schema, crs, encoding, layer, vfs, enabled_drivers, crs_wkt, allow_unsupported_drivers, **kwargs)\u001b[0m\n\u001b[1;32m    332\u001b[0m     path \u001b[38;5;241m=\u001b[39m parse_path(fp)\n\u001b[1;32m    334\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 335\u001b[0m     colxn \u001b[38;5;241m=\u001b[39m \u001b[43mCollection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    337\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    338\u001b[0m \u001b[43m        \u001b[49m\u001b[43mdriver\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdriver\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    339\u001b[0m \u001b[43m        \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    340\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlayer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlayer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    341\u001b[0m \u001b[43m        \u001b[49m\u001b[43menabled_drivers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43menabled_drivers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    342\u001b[0m \u001b[43m        \u001b[49m\u001b[43mallow_unsupported_drivers\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mallow_unsupported_drivers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    343\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    344\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    345\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    346\u001b[0m     colxn \u001b[38;5;241m=\u001b[39m Collection(\n\u001b[1;32m    347\u001b[0m         path,\n\u001b[1;32m    348\u001b[0m         mode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    357\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    358\u001b[0m     )\n",
      "File \u001b[0;32m~/anaconda3/envs/uds/lib/python3.10/site-packages/fiona/collection.py:234\u001b[0m, in \u001b[0;36mCollection.__init__\u001b[0;34m(self, path, mode, driver, schema, crs, encoding, layer, vsi, archive, enabled_drivers, crs_wkt, ignore_fields, ignore_geometry, include_fields, wkt_version, allow_unsupported_drivers, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    233\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m Session()\n\u001b[0;32m--> 234\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msession\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstart\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124ma\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[1;32m    236\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m WritingSession()\n",
      "File \u001b[0;32mfiona/ogrext.pyx:587\u001b[0m, in \u001b[0;36mfiona.ogrext.Session.start\u001b[0;34m()\u001b[0m\n",
      "File \u001b[0;32mfiona/ogrext.pyx:143\u001b[0m, in \u001b[0;36mfiona.ogrext.gdal_open_vector\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mDriverError\u001b[0m: data/nyc_bgs.gpkg: No such file or directory"
     ]
    }
   ],
   "source": [
    "bgs = gpd.read_file('data/nyc_bgs.gpkg')\n",
    "bgs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c295e3d",
   "metadata": {},
   "source": [
    "Note that the variables aren't particularly carefully selected - I just threw in many of the demographic and housing variables. \n",
    "\n",
    "Nor are the variable names particularly informative, but the full names are in a file in the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86627295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note it is tab-sepated, not comma separated\n",
    "# so we use the sep='\\t' argument\n",
    "\n",
    "col_names = pd.read_csv('data/BG_METADATA_2019.txt', sep='\\t', index_col='Short_Name')\n",
    "col_names.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4ea2c7",
   "metadata": {},
   "source": [
    "So you can see the definition of the column like this. (I don't recommend renaming the `bg` column names, because the full names are so long.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f59fcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names.loc['B01001e1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da707b5",
   "metadata": {},
   "source": [
    "#### Spatial join\n",
    "Now let's do the spatial join. Again, let's follow our three step process.\n",
    "\n",
    "1. Use a spatial join to add the `GEOID` column to the evictions dataframe. *Hint:* Check your projections.\n",
    "2. Group by `GEOID` to get a count of evictions per block group. If you have a `Series`, give it a name - maybe `n_evictions`\n",
    "3. Join those counts back - a tabular join based on the index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accd0b18",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <strong>Exercise:</strong> Add a count of evictions per census block group to your <strong>bgs</strong> GeoDataFrame, using the 3-step process above.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc447f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89523f4a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> Do a quick-and-dirty map of the number of evictions. This will help identify any data holes.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2991b6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78b5b4f",
   "metadata": {},
   "source": [
    "#### Random forests regressor\n",
    "Now we have our data set. Let's estimate a random forests model.\n",
    "\n",
    "In contrast to the examples in the lecture, we are trying to predict a continuous variable - the number of evictions. So our classifier isn't appropriate. \n",
    "\n",
    "However, there is a similar model: the [random forest regressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor). It works almost identically to the classifier. The main difference from a user perspective is assessing model performance - a confusion matrix doesn't work here.\n",
    "\n",
    "You'll need to follow the following steps:\n",
    "- choose your x variables. (Your y variable will be `n_evictions`)\n",
    "- Drop Null values if needed\n",
    "- split your dataset into training and testing portions\n",
    "- estimate (fit) the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24327cee",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> Estimate a random forest regressor model to predict the number of evictions per census tract.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192468ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bcc2b6-9bf0-4b15-af65-470a9ea0556e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> Examine some of your trees in the random forest. What do they tell you?</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cb8cb1-3095-443d-a53f-daa59cf698bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83494cfc-07c2-4572-9059-5bdb9c229c15",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> Experiment with different model hyperparameters and variables. Discuss your rationale and the results with a neighbor.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361df43e-8ac4-4394-850b-b787e5a733e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e0ce82-4373-41fe-be47-45a3389eda6a",
   "metadata": {},
   "source": [
    "The following questions relate to some of the material in Module 6. You might want to wait until watching those lectures. Then come back and complete these tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5483eb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> Assess the fit of your model.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aded99af",
   "metadata": {},
   "source": [
    "Remember, the confusion matrix and accuracy scores don't apply to continuous data. Some ideas for continuous variables are [here](https://stackoverflow.com/questions/50789508/random-forest-regression-how-do-i-analyse-its-performance-python-sklearn). You could also plot actual vs predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779701e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f5e2a1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> Which variables are most important in your predictions? Plot the forest importances.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d83e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2818a26",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h3>What you should have learned</h3>\n",
    "<ul>\n",
    "  <li>Get more practice with spatial joins and Socrata.</li>\n",
    "  <li>Learn how to estimate a random forests model for continuous data.</li>\n",
    "</ul>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
